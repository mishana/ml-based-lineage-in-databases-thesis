% This file contains the abstract part of your thesis - in English and
% in Hebrew (within \abstractEnglish and \abstractHebrew respectively).
%
% Notes:
% - This file uses the UTF-8 character set encoding for the Hebrew
%   text not to get garbled. Keep it that way.
% - Assuming your thesis is mainly in English, Graduate School 
%   regulations mandate the following lengths for the abstracts:
%
%      Language    Min. Length   Max. Length
%     ---------------------------------------
%      English       200 words     500 words
%      Hebrew      1,000 words   2,000 words
%
%   so that the Hebrew abstract typically has some content from
%   the English introduction and an overview of the results, not
%   present in the English; it is not just a translation.

\abstractEnglish{

There has been extensive research on data provenance. Previous works were concerned with annotating the results of database (DB) queries with provenance information which is useful in explaining query results at various resolution levels. In this work, we track the lineage of tuples throughout their database lifetime. That is, we consider a scenario in which tuples (records) that are produced by a query may affect other tuple insertions into the DB, as part of a normal workflow. As time goes on, provenance explanations for such tuples become deeply nested, increasingly consuming  space, and resulting in decreased clarity and readability.
\par We present a novel approach for approximating lineage tracking. We use Machine Learning (ML) and Natural Language Processing (NLP) techniques; mainly, word embedding. 
The basic idea is summarizing (and approximating) the lineage of each tuple via a small set of constant-size vectors (the number of vectors per-tuple is a hyperparameter). For explicitly (and independently of DB contents)  inserted tuples -  the vectors are obtained via a pre-trained word vectors model over their underlying database domain ``text". During the execution of a query, we construct the lineage vectors of the final (and intermediate) result tuples in a similar fashion to that of semiring-based exact provenance calculations. We extend the $+$ and $\cdot$ operations to generate sets of lineage vectors, while emphasizing the ability to propagate information and preserve the compact representation. Therefore, our solution does not suffer from space complexity blow-up over time. Another significant benefit of our approach is a ``natural ranking" of explanations to the existence of a tuple in the DB.
\par We devise a genetics-inspired improvement to our basic method. The data columns of an entity (and potentially other columns) are a tuple’s basic properties, i.e., the ``genes" that combine to form its genetic code. In this setting, finding the lineage of a tuple in the DB is analogous to finding its predecessors via DNA examination. We design an alternative lineage tracking mechanism, that of keeping track of and querying lineage (via embeddings) at the column (``gene") level. This way, we manage to better distinguish between the provenance features and the textual characteristics of a tuple.
\par We further introduce several improvements and extensions to the basic method:
\begin{itemize}
    \item Emphasizing important columns with a query-dependent column weighting.
    \item Filtering non-contributing tuples using Bloom Filters of queries.
    \item Filtering non-contributing tuples by a tuple creation timestamp.
    \item Similarity weighting with query dependency DAG.
    \item Extending the method to track where provenance.
\end{itemize}
\par We integrate our lineage computations into the PostgreSQL system via an extension (ProvSQL) and experimentally exhibit useful results in terms of accuracy against exact, semiring-based, justifications.  In the experiments, we focus on tuples with multiple generations of tuples in their lifelong lineage and analyze them in terms of direct and distant lineage. The examples we present suggest a high usefulness potential for the proposed approximate lineage methods and the further suggested enhancements. This especially holds for the column-based vectors method which exhibits high precision and per-level recall.
\par Finally, to practically realize our methods, we need to search efficiently for a set of vectors that maximizes set-wise similarity. We outline such a search algorithm, which is based on encoding a set of vectors via a ``long" single vector. 


} % end of English abstract


\abstractHebrew{

% Note that certain commands don't work that well in Hebrew "mode".
% If this happens to you, try wrapping the command within a
% \textenglish{ } - that may (or may not) help.

יוחסין של נתונים הוא נושא שנחקר רבות בשנים האחרונות.
עבודות קודמות עסקו בתיוג של תוצאות שאילתות על גבי מסדי נתונים על ידי ׳׳מטא נתונים״ המעידים על היוחסין של התוצאות.
מטא נתונים אלה הוכחו כשימושיים בהסבר של תוצאות שאילתות ברמות פירוט שונות.

במחקר זה אנו שואפים להתחקות אחר המוצאות של רשומות במסדי נתונים לאורך חייהן, תוך הבחנה בין רשומות שהוכנסו באופן ידני ובלתי תלוי בתכולת מסד הנתונים (אלו ״אבני הבנין״ שלנו) לבין רשומות הנוצרות על ידי שאילתא (או, באופן כללי, אשר תלויות בתוכן מסד הנתונים).
כלומר, אנחנו מניחים תסריט שבו רשומות הנוצרות על ידי שאילתא עלולות להשפיע על הכנסתן של רשומות אחרות למסד הנתונים, וזאת כחלק מתזרים עבודה תקני של המערכת.
בתרחיש אמיתי - רשומות שתלויות בתכולת מסד הנתונים יווצרו באחת מהדרכים הבאות:
(1) היררכיה של  
    מבטים מתוחזקים -
    כך שכל 
    מבט
    יכול להיות תלוי הן בתכולת מסד הנתונים והן
    במבטים
    שהוגדרו בשלב מוקדם יותר;
    (2) רשומות אשר מוכנסות למסד הנתונים באמצעות פקודת 
    \textenglish{\texttt{INSERT INTO SELECT}};
    (3) רשומות אשר מוכנסות למסד הנתונים באמצעות פקודת 
    \textenglish{\texttt{UPDATE}};
    (4) תוצאת שאילתא עם שדות שהוספו באופן ידני, אשר מוכנסת בחזרה לטבלה אחרת במסד הנתונים.

עם חלוף הזמן, אילנות היוחסין (וההסברים הנובעים מהם) של רשומות אלה הופכים מקוננים ומסובכים מאוד מבחינת צריכת זיכרון, זמן חישוב עבור מוצאות רשומות, בהירות וקריאות. 
אנו מציגים גישה חדשה לחישוב מקורב של מוצאות רשומות תוך שימוש בטכניקות של למידת מכונה ועיבוד שפה טבעית (ובעיקר, שיכון מילים במרחב אוקלידי).

הרעיון המרכזי הוא לסכם (באופן מקורב) את היוחסין של כל רשומה על ידי קבוצה סופית של וקטורים (מספר הוקטורים פר-רשומה הוא היפרפרמטר של המערכת).
עבור רשומות המוכנסות למסד הנתונים באופן ידני - הוקטורים מחושבים באמצעות מודל מאומן מראש של וקטורי מילה על גבי ה״טקסט״ של הרשומות.
בזמן תהליך ביצוע של שאילתא על גבי מסד הנתונים, אנו מחשבים את וקטורי היוחסין של הרשומות החדשות בתוצאה של השאילתא באופן דומה לחישוב מדוייק המבוסס חצאי-חוגים (מבנה אלגברי).
אנו מכלילים את פעולות החיבור והכפל לעבודה על קבוצות של וקטורי יוחסין, תוך שימת דגש על היכולת לפעפע את מידע היוחסין ושמירה על הייצוג הקומפקטי של מספר סופי וחסום של וקטורי יוחסין פר-רשומה.
\newpage
כתוצאה, אנחנו מקבלים קבוצות של וקטורי יוחסין עבור רשומות בתוצאה של שאילתא. רשומות חדשות אלה (והמידע בעניין מוצאותיהן) עשויות להתווסף למסד הנתונים בשלב מאוחר יותר (כתלות ביישום הספציפי).

אנו מציגים שיפור משמעותי לשיטה הבסיסית (שפיתחנו) בהשראת אנאלוגיה לתחום הגנטי.
העמודות של יישות (ופוטנציאלית עמודות נוספות) הן המאפיינים הבסיסיים של רשומה באותה יישות, כלומר, הגנים שמרכיבים את הקוד הגנטי שלה.
תחת הנחות אלה, מציאת המוצאות של רשומה במסד הנתונים שקולה למציאת האבות הקדמונים שלה באמצעות בדיקות דנ״א.
אם כך, אנו מציעים לתחזק ולחפש מוצאות של רשומות באמצעות וקטורי יוחסין ברמת העמודות (גנים) ולא ברמת רשומות שלמות. בצורה זו, אנו מצליחים להבחין בצורה טובה יותר בין תכונות היוחסין לבין המאפיינים הטקסטואליים של רשומה.

לאחר תיאור הרעיון המרכזי, אנו מציגים שיפורים והרחבות לשיטה, שנועדו להפוך אותה לפרקטית ושימושית עבור אנאליסט. אותו אנאליסט, שירצה להשתמש בוקטורי היוחסין על מנת למצוא את מוצאותיה של רשומה ספציפית במסד הנתונים, יוכל לעשות זאת על ידי השוואה בין וקטורי היוחסין של הרשומה לוקטורי היוחסין של קבוצת עניין במסד הנתונים (כל קבוצה של רשומות), ולדרג אותן לפי ״קירבה״ - באופן דומה למתודולוגיה של חיפוש מילים קרובות סמנטית באמצעות השוואת וקטורי מילה.

אנו משלבים את החישוב המקורב של מוצאות רשומות במערכת לניהול מסדי נתונים
\textenglish{PostgreSQL}
באמצעות ההרחבה
\textenglish{ProvSQL}
ומציגים תוצאות בעלות תועלת מבחינת דיוק בהשוואה לחישוב מדויק המבוסס חצאי-חוגים.
אנו טוענים כי הפיתרון המוצע אינו סובל מניפוח יתר בסיבוכיות מקום לאורך זמן,
ולכן הופך מערכת לחקר יוחסין של רשומות ברת ביצוע תחת האילוצים שתוארו לעיל.
יתרון משמעותי של השיטה שלנו הוא ״דירוג טבעי״ של מוצאות רשומות.

לסיום, כדי לתמוך במימוש יעיל, אנו זקוקים לשיטה של חיפוש קבוצה של וקטורים הקרובה ביותר לקבוצה נתונה. 
אנו מציגים שיטת חיפוש כזו המבוססת על הרעיון של ייצוג של קבוצת וקטורים באמצעות וקטור ״ארוך״ בודד.

% בית הספר ללימודי מוסמכים מנחה מספר הנחיות לגבי התקציר בעברית:
% \begin{itemize}
% \item על התקציר להיכתב במשפטים מקושרים שלמים.
% \item בדרך-כלל אין לציין בתקציר מקורות ספרותיים וציטוטים.
% \item אין להתייחס למספר של פרק, סעיף, נוסחה, ציור או טבלה שבגוף החיבור, ואין להשתמש בקיצורים, סמלים ומונחים לא מקובלים, אלא אם יש בתקציר די מקום לזיהויים.
% \end{itemize}



% \subsection*{\texthebrew{תת-חלק בתקציר המורחב}}

% תוכן מקוצר לגבי נושא מסוים. התייחסות ל\emph{מושג} מסוים שהחיבור בוחן. וכולי וכולי.


% \subsection*{\texthebrew{נקודה מעניינת לגבי העמודים בעברית}}

% שימו לב כי העמודים בעברית אמורים להיות מיוצרים בסדר ה''הפוך'', הווה אומר העמוד האחרון בקובץ ה-\textenglish{PDF} הוא הכריכה העברית, לפניו השער העברי, ודפי התקציר צריכים להופיע בסדר הפוך (וכן במספור רומי, לפי נהלי הטכניון). כך אם נתבונן במספר שבתחתית עמוד זה \textenglish{---} אשר צריך להיות העמוד הראשון בתקציר-המורחב מבחינת רצף התוכן, והינו העמוד האחרון מבין עמודי התקציר-המורחב אחרון בקובץ ה-\textenglish{PDF} \textenglish{---} נמצא את המספר \textenglish{i} ...

% \newpage

% ... ואילו עמוד זה של התקציר-המורחב בעברית \textenglish{---} שהינו העמוד השני בתקציר-המורחב מבחינת רצף התוכן, ונמצא ראשון בקובץ ה-\textenglish{PDF} \textenglish{---} ממוספר ב-\textenglish{ii}. המטרה במספור בסדר ה"הפוך" היא, שבעת ההדפסה לא יהיה צורך להפוך דפים, לשנות את סדרם וכולי \textenglish{---} רק להדפיס ולכרוך.

} % end of Hebrew abstract
